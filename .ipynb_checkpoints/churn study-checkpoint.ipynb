{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "take the oppportunity to figure out how to use grid search\n",
    "- ROC Curve or AUC Curve - ROC is curve - and AUC is a number \n",
    "- framework of models\n",
    "- partial dependency plots\n",
    "- base-model, logistic regression\n",
    "- interpretation, *feature importance*\n",
    "- interpratation - linear regression\n",
    "\n",
    "\n",
    "### to evaluate:\n",
    "GridSearchCV\n",
    "roc_auc_score\n",
    "cross_val_score - accuracy\n",
    "\n",
    "def cv_train_scores\n",
    "def stage_score_plot\n",
    "def plot_feature_importances\n",
    "def change_num_features\n",
    "\n",
    "def neural_network\n",
    "\n",
    "\n",
    "### potential models - would be worth looking at their attributes too\n",
    "SVC\n",
    "    - hyper parameters\n",
    "        - there are options, I just don't understand them\n",
    "RandomForestRegressor\n",
    "    - hyper parameters \n",
    "        - number of regressors\n",
    "        - number of features per node\n",
    "GradientBoostingRegressor\n",
    "    - hyper parameters\n",
    "        - learning rate\n",
    "        - number of regressors\n",
    "        - subsample size\n",
    "        - max_depth\n",
    "MLPClassifier\n",
    "    - hyper parameters\n",
    "        - hidden_layer_sizes: tuple,length = n_layers - 2, default (100,)\n",
    "        - activation: default ‘relu’\n",
    "        - alpha : float, optional, default 0.0001 (L2 penalty - regularization)\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hypothetically auto reload\n",
    "import importlib\n",
    "import churn_eval #import the module here, so that it can be reloaded.\n",
    "importlib.reload(churn_eval)\n",
    "\n",
    "import importlib\n",
    "import clean #import the module here, so that it can be reloaded.\n",
    "importlib.reload(clean)\n",
    "\n",
    "# import regressors\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# import evaluations tools\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score, roc_auc_score\n",
    "\n",
    "# import plotting and libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,\"/Users/sarahburgart/galvanize/week6/random-forests/src/\")\n",
    "\n",
    "import roc\n",
    "from roc import plot_roc\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_raw = pd.read_csv(\"/Users/sarahburgart/galvanize/week6/churn_case_study/supervised-learning-case-study/data/churn.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create target\n",
    "clean.active_flag(churn_raw, 'last_trip_date')\n",
    "y = churn_raw.active_flag\n",
    "X = churn_raw.drop(\"active_flag\", axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean data\n",
    "X = clean.clean_data(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = [(\"MLPClassifier\", \"train accuracy: 0.731\", \"test accuracy: 0.735\"),\n",
    "        ]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.761 | test_score: 0.760 | params: {'activation': 'relu', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'max_iter': 200, 'momentum': 0.9, 'n_iter_no_change': 10, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': None, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "mlp_basic = churn_eval.neural_network(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sarahburgart/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "svc = SVC()\n",
    "mlp = MLPClassifier()\n",
    "rfr = RandomForestRegressor()\n",
    "gbr = GradientBoostingRegressor(learning_rate=.001, n_estimators=1000, \n",
    "                               subsample=.8)\n",
    "\n",
    "mods = [svc, mlp, rfr, gbr]\n",
    "models = [x.fit(X_train,y_train) for x in mods]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,8))\n",
    "#fig.figsize=(28,14)\n",
    "ax.set_title([\"improvement in loss on the out-of-bag samples relative to the previous iteration\"])\n",
    "for i in [.1,.2,.3,.4,.5,.6,.7,.8,.9]:\n",
    "    gbr = GradientBoostingRegressor(learning_rate=.001, n_estimators=1000, \n",
    "                               subsample=i)\n",
    "    gbr.fit(X_train, y_train)\n",
    "    ax.plot(gbr.oob_improvement_, label=f\"{i}\")\n",
    "    \n",
    "\n",
    "#ax.title([\"improvement in loss on the out-of-bag samples relative to the previous iteration\"])\n",
    "ax.set_xlabel(\"iteration\")\n",
    "ax.set_ylabel(\"improvement\")\n",
    "fig.legend(loc='upper right');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "churn_eval.cv_train_scores(models, X, y, 'accuracy', 'roc_auc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_eval.stage_score_plot(GradientBoostingRegressor, X_train, y_train, X_test, y_test,\n",
    "                            learning_rate=.001,n_estimators=10000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_auc = roc_auc_score(y_test, mods[3].predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
